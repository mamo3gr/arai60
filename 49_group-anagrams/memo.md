## step 1

単語の列が与えられるので、アナグラムごとにグルーピングして返す。  
例えばnatとtanはアナグラムの関係になっているが、ソートして一致する、あるいは文字の出現数のヒストグラムが一致することと同値である。これらをkey、単語のリストをvalueにしたdict（ハッシュマップ）に詰めていけばよい。

単語はアルファベットの小文字からなり、最長で100文字。つまりヒストグラムは26次元になる。単語数は最大で10^4個。単語数を `N`, 単語長を `W` として時間計算量と空間計算量を見積もってみる。

### ソートする場合

まずは時間計算量。N個の単語それぞれについて、単語のソートに `O(W log W)`, ハッシュマップを引いてlistへ追加するのはどちらも `O(1)`. できたハッシュマップから答えの形へ変換するのに `O(N)` かかる。つまり全体で `O(NW log W)`.

空間計算量は `O(N)`. 1文字1バイトとして単語あたり100バイト * N個で100 bytes * 10^4 = 1MB. ハッシュマップのkeyも持つ必要があるが高々倍（すべての単語がユニークの場合）。

### ヒストグラムを使う場合

時間計算量は、単語からヒストグラムを作るのに `O(W)`. それ以外はソートする場合と変わらない。したがって `O(NW)`.

空間計算量は `O(N)`. 26次元のヒストグラムは、intあたり28bytes * 26 = 728bytes. これを最大N個持つことになる。728 bytes * 10^4 = 7.28MB. ソートの場合とオーダーは変わらない（がちょっと多い）。

### 意思決定

ソートにする。時間計算量は単語数が支配的だろうから、ヒストグラムを作るのがソートよりも速くても、その寄与は小さいことが予想される。空間計算量のオーダーは変わらない（たぶんソートの場合の法が多少有利）。コードの簡潔さはソートの方が有利そうで、ここが個人的に大きい（ヒストグラムをタプルで作って…みたいなのが面倒）。

## step 2

`normalized_` によりよい命名の余地がありそう。

### 他の人のコード

https://github.com/katsukii/leetcode/pull/6#discussion_r1899084266

>ところで、アルファベットでないものが入ってきたら、このコードは何が起きるでしょうか。

現状のコードだと、アルファベット小文字以外の文字も合わせてアナグラムかどうかを判断している。  
よくあるケースとしては、大文字や、空白などの記号が混ざっていてグルーピングに失敗することが予想される。  
実務的には、

* 想定されていない文字を含む単語を処理せず、ログに落とす（warningレベルなど）
* 想定されていない文字を除外して処理し、ログに落とす
* 関数（処理）自体をraiseする

あたりが考えられる。

https://github.com/komdoroid/arai60/blob/14ec1184d68b0514455e688bdfc2ef39e1d787d8/HashMap/49.GroupAnagrams/memo.md

`sorted_` なるほど。ちょっとhowに踏み込んでいる気もするが。

https://github.com/komdoroid/arai60/pull/2/files#r2554617171

>文字列を再構築せずtupleにする

たしかに。

https://github.com/docto-rin/leetcode/blob/a2d090a70d9800051af93c23758ce30825c58f26/0049-group-anagrams/0049-group-anagrams.md

文字ごとのヒストグラムでの実装例。問題ではアルファベットの小文字だけなのでコードポイントも連続しているが、他の文字種が入ってくると扱いが大変そうだ。例えばa-zは97–122だが、A-Zは65-90で間が空いている。

### コメント集

https://docs.google.com/document/d/11HV35ADPo9QxJOpJQ24FcZvtvioli770WWdZZDaLOfg/edit?tab=t.0#heading=h.e5dwa7yj3tv0

frozensetを使うという選択肢も。setとは違い、immutableかつhashable.  
https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset
